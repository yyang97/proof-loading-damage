{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "90dff0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.integrate import quad,fixed_quad\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "from scipy.optimize import minimize\n",
    "import joblib\n",
    "import pandas as pd\n",
    "# Equivalent to R's logit function\n",
    "def logit(x):\n",
    "    return np.log(x / (1 - x))\n",
    "\n",
    "# Equivalent to R's expit function\n",
    "def expit(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# Bivariate normal PDF\n",
    "# Equivalent to R's biv_pdf function\n",
    "def biv_pdf(x, y, mu, sigma, rho, log=False):\n",
    "    rho_part = 1 - rho**2\n",
    "    if rho_part <= 0:\n",
    "        rho_part = 0.000001  # To prevent division by zero or negative values\n",
    "\n",
    "    factor_part = 2 * np.pi * sigma[0] * sigma[1] * np.sqrt(rho_part)\n",
    "    exp_part = ((x - mu[0]) / sigma[0])**2 + ((y - mu[1]) / sigma[1])**2\n",
    "    exp_part -= 2 * rho * (x - mu[0]) * (y - mu[1]) / (sigma[0] * sigma[1])\n",
    "    exp_part = -exp_part / (2 * rho_part)\n",
    "\n",
    "    if log:\n",
    "        return exp_part - np.log(factor_part)\n",
    "    else:\n",
    "        return np.exp(exp_part) / factor_part\n",
    "\n",
    "# Equivalent to R's dmg_int_inner function\n",
    "def dmg_int_inner(x, y, mu, sigma, rho, eta, alpha, l):\n",
    "    sd_x = sigma[0]\n",
    "    sd_y = sigma[1]\n",
    "    # Adjusted value of y\n",
    "    adjusted_y = y + (mu[1] / mu[0]) * alpha * (l / eta - x)\n",
    "    return biv_pdf(x, adjusted_y, mu, sigma, rho)\n",
    "\n",
    "\n",
    "def dmg_int(y, mu, sigma, rho, eta, alpha, l):\n",
    "    # Use scipy's quad to perform the integration\n",
    "    result, _ = quad(dmg_int_inner, l, l / eta, args=(y, mu, sigma, rho, eta, alpha, l), epsabs=1e-5)\n",
    "    return result\n",
    "# Equivalent to R's dmg_int function\n",
    "# def dmg_int(y, mu, sigma, rho, eta, alpha, l):\n",
    "#     # Define the adjusted parameters\n",
    "#     adjusted_mean = mu[0] + (mu[1] / mu[0]) * alpha * (l / eta - mu[0])\n",
    "#     adjusted_sd = sigma[0]\n",
    "    \n",
    "#     # Use Gaussian quadrature for the integration with a moderate number of points (n=10)\n",
    "#     result, _ = fixed_quad(dmg_int_inner, l, l / eta, args=(y, mu, sigma, rho, eta, alpha, l), n=10)\n",
    "#     return result\n",
    "\n",
    "\n",
    "def dmg_model(samples, eta, alpha, l, mu):\n",
    "    # Check if l > samples[:, 0] * eta for each row\n",
    "    condition = l > samples[:, 0] * eta\n",
    "    adjusted_values = samples[:, 1] - (mu[1] / mu[0]) * alpha * (l / eta - samples[:, 0])\n",
    "    \n",
    "    # If condition is True, calculate damage; otherwise, use undamaged value\n",
    "    return np.where(condition, adjusted_values, samples[:, 1])\n",
    "def int_function(y_star, mu, sigma, rho, l):\n",
    "    a_l = (l - mu[0] - rho * (sigma[0] / sigma[1]) * (y_star - mu[1])) / (sigma[0] * np.sqrt(1 - rho**2))\n",
    "    return norm.pdf(y_star, loc=mu[1], scale=sigma[1]) * (1 - norm.cdf(a_l))\n",
    "\n",
    "\n",
    "def PFY_lik(mu, sigma, rho, eta, alpha, l, data):\n",
    "    # Part 1: Log-likelihood for data where data[:, 2] == 1\n",
    "    part_1 = np.sum(norm.logpdf(data[data[:, 2] == 1, 0], loc=mu[0], scale=sigma[0]))\n",
    "    \n",
    "    # Extract y values where data[:, 2] == 0\n",
    "    y_values = data[data[:, 2] == 0, 1]\n",
    "\n",
    "    # Use numpy's vectorize to apply dmg_int to all y values\n",
    "    vectorized_dmg_int = np.vectorize(lambda y: fixed_quad(dmg_int_inner, l, l / eta, args=(y, mu, sigma, rho, eta, alpha, l), n=10)[0])\n",
    "    dmg_int_values = vectorized_dmg_int(y_values)\n",
    "\n",
    "    # Vectorized computation for int_function_values\n",
    "    int_function_values = int_function(y_values, mu, sigma, rho, 1 / eta * l)\n",
    "    #int_function_values = np.array([int_function(y, mu, sigma, rho, 1/eta * l) for y in data[data[:, 2] == 0, 1]])\n",
    "\n",
    "\n",
    "    # Summing the log of the combined dmg_int_values and int_function_values\n",
    "    part_2 = np.sum(np.log(dmg_int_values + int_function_values))\n",
    "    \n",
    "    return part_1 + part_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pl_gen(mu, sigma, rho, eta, alpha, l, N):\n",
    "    # Covariance matrix\n",
    "    cov_matrix = np.array([\n",
    "        [sigma[0]**2, sigma[0] * sigma[1] * rho],\n",
    "        [sigma[0] * sigma[1] * rho, sigma[1]**2]\n",
    "    ])\n",
    "    # Generate samples from bivariate normal distribution\n",
    "    samples = np.random.multivariate_normal(mean=mu, cov=cov_matrix, size=N)\n",
    "    res = np.zeros((samples.shape[0], samples.shape[1] + 1))\n",
    "    \n",
    "    # Fail in the proof loading\n",
    "    fail_ids = samples[:, 0] < l\n",
    "    res[fail_ids, 0] = samples[fail_ids, 0]\n",
    "    res[fail_ids, 2] = 1\n",
    "    \n",
    "    # Survive in the proof loading\n",
    "    survive_ids = samples[:, 0] >= l\n",
    "    res[survive_ids, 1] = dmg_model(samples[survive_ids], eta, alpha, l, mu)\n",
    "    res[survive_ids, 2] = 0\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f6f74877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (requires biv_pdf to be implemented)\n",
    "mu = [45, 5.5]\n",
    "sigma = [13, 1]\n",
    "rho = .7\n",
    "eta = .7\n",
    "alpha = 0\n",
    "\n",
    "# rho = correlation_coefficient\n",
    "N = 87\n",
    "np.random.seed(0)\n",
    "R_pf = norm.ppf([0.2, 0.4, 0.6], loc=mu[0], scale=sigma[0])\n",
    "T_pf = norm.ppf([0.2, 0.4, 0.6], loc=mu[1], scale=sigma[1])\n",
    "l = R_pf[2]\n",
    "pf_data = pl_gen(mu, sigma, rho, eta, alpha, l, N)\n",
    "#print(pf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1a4d0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0  = [mu[0],mu[1],\n",
    "           sigma[0],sigma[1],logit(rho),logit(eta),alpha]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "77049da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-277.84386718236226"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-277.84386718236226\n",
    "\n",
    "PFY_lik(mu, sigma, rho, eta, alpha, l, pf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53694a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c872d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_checkR(theta, R_group, T_group, R_pl, T_pl, shoulder_group):\n",
    "    mu = theta[0:2]\n",
    "    sigma = theta[2:4]\n",
    "    rho = expit(theta[4])\n",
    "    eta = expit(theta[5])\n",
    "    alpha = theta[6]\n",
    "    \n",
    "    # Likelihood calculations\n",
    "    lik = (PFY_lik(mu, sigma, rho, 1, 0, R_pl, R_group) +\n",
    "           PFY_lik([mu[1], mu[0]], [sigma[1], sigma[0]], rho, eta, alpha, T_pl, T_group) +\n",
    "           np.sum(norm.logpdf(shoulder_group[0], loc=mu[0], scale=sigma[0])) +\n",
    "           np.sum(norm.logpdf(shoulder_group[1], loc=mu[1], scale=sigma[1])))\n",
    "    \n",
    "    # Handle infinite likelihood\n",
    "    if np.isinf(lik):\n",
    "        lik = -10000\n",
    "    \n",
    "    return -1 * lik\n",
    "\n",
    "def single_fitalpha(theta, group, group_pl, group_name, shoulder_group):\n",
    "    mu = theta[0:2]\n",
    "    sigma = theta[2:4]\n",
    "    rho = theta[4]\n",
    "    eta = theta[5]\n",
    "    alpha = theta[6]\n",
    "    \n",
    "    if group_name == \"R\":\n",
    "        lik = PFY_lik(mu, sigma, rho, eta, alpha, group_pl, group)\n",
    "    elif group_name == \"T\":\n",
    "        lik = PFY_lik([mu[1], mu[0]], [sigma[1], sigma[0]], rho, eta, alpha, group_pl, group)\n",
    "    \n",
    "    lik += (np.sum(norm.logpdf(shoulder_group[0], loc=mu[0], scale=sigma[0])) +\n",
    "            np.sum(norm.logpdf(shoulder_group[1], loc=mu[1], scale=sigma[1])))\n",
    "    \n",
    "    if np.isinf(lik):\n",
    "        lik = -10000\n",
    "    \n",
    "    return -1 * lik\n",
    "\n",
    "# Equivalent to R's single_alpha0 function\n",
    "def single_alpha0(theta, group, group_pl, group_name, shoulder_group):\n",
    "    mu = theta[0:2]\n",
    "    sigma = theta[2:4]\n",
    "    rho = expit(theta[4])\n",
    "    \n",
    "    if group_name == \"R\":\n",
    "        lik = PFY_lik(mu, sigma, rho, 1, 0, group_pl, group)\n",
    "    elif group_name == \"T\":\n",
    "        lik = PFY_lik([mu[1], mu[0]], [sigma[1], sigma[0]], rho, 1, 0, group_pl, group)\n",
    "    \n",
    "    lik += (np.sum(norm.logpdf(shoulder_group[0], loc=mu[0], scale=sigma[0])) +\n",
    "            np.sum(norm.logpdf(shoulder_group[1], loc=mu[1], scale=sigma[1])))\n",
    "    \n",
    "    if np.isinf(lik):\n",
    "        lik = -10000\n",
    "    \n",
    "    return -1 * lik\n",
    "\n",
    "\n",
    "\n",
    "def ecdf(x):\n",
    "    x = np.sort(x)\n",
    "    n = len(x)\n",
    "    def _ecdf(v):\n",
    "        # side='right' because we want Pr(x <= v)\n",
    "        return (np.searchsorted(x, v, side='right') + 1) / n\n",
    "    return _ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "334d4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "pf_data = pl_gen(mu, sigma, rho, eta, alpha, l, N)\n",
    "R100_data = np.random.normal(loc=mu[0], scale=sigma[0], size=2 * N)\n",
    "T100_data = np.random.normal(loc=mu[1], scale=sigma[1], size=2 * N)\n",
    "shoulder_group = [R100_data, T100_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a2e45f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrt_fit(jj,theta):\n",
    "    np.random.seed(jj)  # Set seed for reproducibility\n",
    "    pf_data = pl_gen(mu, sigma, rho, eta, alpha, l, N)\n",
    "    R100_data = np.random.normal(loc=mu[0], scale=sigma[0], size=2 * N)\n",
    "    T100_data = np.random.normal(loc=mu[1], scale=sigma[1], size=2 * N)\n",
    "    shoulder_group = [R100_data, T100_data]\n",
    "\n",
    "\n",
    "\n",
    "    optim_checkR = minimize(single_alpha0, theta0[0:5], args=(pf_data, l, \"R\", shoulder_group),\n",
    "                           method = \"Nelder-Mead\")\n",
    "    llr_checkR = 2 * optim_checkR.fun\n",
    "    theta_est = optim_checkR.x\n",
    "    # # Optimization step for single_fitalpha\n",
    "    bounds = [(30, 70), (0.1, 40), (0.1, 30), (0.1, 10), (0.01, 0.99), (0.01, 0.99), (-2, 10)]\n",
    "    optimout = minimize(single_fitalpha, theta0, \n",
    "                        args=(pf_data,l, \"R\", shoulder_group), \n",
    "                        method=\"L-BFGS-B\", bounds=bounds)\n",
    "    llr_full = 2 * optimout.fun\n",
    "    llr_stat = llr_checkR - llr_full\n",
    "    return [jj,llr_stat,*theta_est.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "eadc7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrt_sim(jj,theta):\n",
    "    np.random.seed(jj)  # Set seed for reproducibility\n",
    "    mu = theta[0:2]\n",
    "    sigma = theta[2:4]\n",
    "    rho = expit(theta[4])\n",
    "    pf_data = pl_gen(mu, sigma, rho, 1,0, l, N)\n",
    "    R100_data = np.random.normal(loc=mu[0], scale=sigma[0], size=2 * N)\n",
    "    T100_data = np.random.normal(loc=mu[1], scale=sigma[1], size=2 * N)\n",
    "    shoulder_group = [R100_data, T100_data]\n",
    "\n",
    "\n",
    "\n",
    "    optim_checkR = minimize(single_alpha0, theta0[0:5], args=(pf_data, l, \"R\", shoulder_group),\n",
    "                           method = \"Nelder-Mead\")\n",
    "    llr_checkR = 2 * optim_checkR.fun\n",
    "    theta_est = optim_checkR.x\n",
    "    # # Optimization step for single_fitalpha\n",
    "    bounds = [(30, 70), (0.1, 40), (0.1, 30), (0.1, 10), (0.03, 0.97), (0.03, 0.97), (-2, 10)]\n",
    "    optimout = minimize(single_fitalpha, theta0, \n",
    "                        args=(pf_data,l, \"R\", shoulder_group), \n",
    "                        method=\"L-BFGS-B\", bounds=bounds)\n",
    "    llr_full = 2 * optimout.fun\n",
    "    llr_stat = llr_checkR - llr_full\n",
    "    return [jj,llr_stat,*theta_est.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "01400f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11801250457847345\n",
      "0.3889279365539551\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "ii = 5\n",
    "np.random.seed(ii)  # Set seed for reproducibility\n",
    "pf_data = pl_gen(mu, sigma, rho, eta, alpha, l, N)\n",
    "R100_data = np.random.normal(loc=mu[0], scale=sigma[0], size=2 * N)\n",
    "T100_data = np.random.normal(loc=mu[1], scale=sigma[1], size=2 * N)\n",
    "shoulder_group = [R100_data, T100_data]\n",
    "\n",
    "\n",
    "\n",
    "optim_checkR = minimize(single_alpha0, theta0[0:5], args=(pf_data, l, \"R\", shoulder_group),\n",
    "                       method = \"Nelder-Mead\")\n",
    "llr_checkR = 2 * optim_checkR.fun\n",
    "theta_est = optim_checkR.x\n",
    "# # Optimization step for single_fitalpha\n",
    "bounds = [(30, 70), (0.1, 40), (0.1, 30), (0.1, 10), (0.01, 0.99), (0.01, 0.99), (-2, 10)]\n",
    "optimout = minimize(single_fitalpha, theta0, \n",
    "                    args=(pf_data,l, \"R\", shoulder_group), \n",
    "                    method=\"L-BFGS-B\", bounds=bounds)\n",
    "llr_full = 2 * optimout.fun\n",
    "llr_stat = llr_checkR - llr_full\n",
    "end_time = time.time()\n",
    "print(llr_stat)\n",
    "print(end_time - start_time)\n",
    "#2.080707936768704\n",
    "# 3.4158260822296143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31a0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
